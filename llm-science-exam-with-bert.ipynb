{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d375257a",
   "metadata": {
    "papermill": {
     "duration": 0.007779,
     "end_time": "2023-09-01T09:45:35.369483",
     "exception": false,
     "start_time": "2023-09-01T09:45:35.361704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LLM Science Exam\n",
    "\n",
    "This starter notebook walks through a basic example of using BERT to rank the answers to each question. We'll finetune BERT on the 200 public questions, then use the AutoModelForMultipleChoice class to generate probabilities that each option correctly answers the prompt, and finally we'll turn those predictions into a MAP@3-formatted prediction like `A B C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269cde46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:35.385084Z",
     "iopub.status.busy": "2023-09-01T09:45:35.384693Z",
     "iopub.status.idle": "2023-09-01T09:45:35.464452Z",
     "shell.execute_reply": "2023-09-01T09:45:35.463425Z"
    },
    "papermill": {
     "duration": 0.091572,
     "end_time": "2023-09-01T09:45:35.468128",
     "exception": false,
     "start_time": "2023-09-01T09:45:35.376556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\n",
      "/kaggle/input/kaggle-llm-science-exam/train.csv\n",
      "/kaggle/input/kaggle-llm-science-exam/test.csv\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-cased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/whole-word-masking/._bert_config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/whole-word-masking/bert_config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-uncased/whole-word-masking/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/whole-word-masking/._bert_config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/whole-word-masking/bert_config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased/whole-word-masking/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/cl-tohoku/bert-base-japanese-whole-word-masking/config.json\n",
      "/kaggle/input/huggingface-bert/cl-tohoku/bert-base-japanese-whole-word-masking/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/cl-tohoku/bert-base-japanese-whole-word-masking/tokenizer_config.json\n",
      "/kaggle/input/huggingface-bert/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/cl-tohoku/bert-base-japanese-whole-word-masking/vocab.txt\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/rust_model.ot\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/config.json\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/tokenizer_config.json\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/modelcard.json\n",
      "/kaggle/input/huggingface-bert/dbmdz/bert-large-cased-finetuned-conll03-english/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/config.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-large-cased-whole-word-masking/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-base-cased/flax_model.msgpack\n",
      "/kaggle/input/huggingface-bert/bert-base-german-cased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-german-cased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-german-cased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-german-cased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-german-cased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-multilingual-uncased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/config.json\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/tokenizer_config.json\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/modelcard.json\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/special_tokens_map.json\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/vocab.txt\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/added_tokens.json\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/saved_model/saved_model.pb\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/saved_model/variables/variables.index\n",
      "/kaggle/input/huggingface-bert/deepset/bert-large-uncased-whole-word-masking-squad2/saved_model/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-chinese/vocab.txt\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/rust_model.ot\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/config.json\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/tokenizer.json\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/tf_model.h5\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/modelcard.json\n",
      "/kaggle/input/huggingface-bert/bert-base-uncased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/config.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/tokenizer_config.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/special_tokens_map.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-uncased/added_tokens.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/config.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/tokenizer_config.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/pytorch_model.bin\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/special_tokens_map.json\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/vocab.txt\n",
      "/kaggle/input/huggingface-bert/dccuchile/bert-base-spanish-wwm-cased/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78d06e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:35.483563Z",
     "iopub.status.busy": "2023-09-01T09:45:35.483282Z",
     "iopub.status.idle": "2023-09-01T09:45:35.519624Z",
     "shell.execute_reply": "2023-09-01T09:45:35.518771Z"
    },
    "papermill": {
     "duration": 0.046592,
     "end_time": "2023-09-01T09:45:35.521872",
     "exception": false,
     "start_time": "2023-09-01T09:45:35.475280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "2   2  Which of the following statements accurately d...   \n",
       "3   3  What is the significance of regularization in ...   \n",
       "4   4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E answer  \n",
       "0  MOND is a theory that eliminates the observed ...      D  \n",
       "1  Dynamic scaling refers to the evolution of sel...      A  \n",
       "2  The triskeles symbol is a representation of th...      A  \n",
       "3  Regularizing the mass-energy of an electron wi...      C  \n",
       "4  The angular spacing of features in the diffrac...      D  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import the public training set and take a look\n",
    "train_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed7dcc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:35.538612Z",
     "iopub.status.busy": "2023-09-01T09:45:35.538304Z",
     "iopub.status.idle": "2023-09-01T09:45:36.374128Z",
     "shell.execute_reply": "2023-09-01T09:45:36.373062Z"
    },
    "papermill": {
     "duration": 0.847075,
     "end_time": "2023-09-01T09:45:36.376943",
     "exception": false,
     "start_time": "2023-09-01T09:45:35.529868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For convenience we'll turn our pandas Dataframe into a Dataset\n",
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004921d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:36.394547Z",
     "iopub.status.busy": "2023-09-01T09:45:36.394051Z",
     "iopub.status.idle": "2023-09-01T09:45:38.520250Z",
     "shell.execute_reply": "2023-09-01T09:45:38.519276Z"
    },
    "papermill": {
     "duration": 2.137436,
     "end_time": "2023-09-01T09:45:38.522536",
     "exception": false,
     "start_time": "2023-09-01T09:45:36.385100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# The path of the model checkpoint we want to use\n",
    "model_dir = '/kaggle/input/huggingface-bert/bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39456885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:38.540173Z",
     "iopub.status.busy": "2023-09-01T09:45:38.539093Z",
     "iopub.status.idle": "2023-09-01T09:45:39.031979Z",
     "shell.execute_reply": "2023-09-01T09:45:39.031087Z"
    },
    "papermill": {
     "duration": 0.503587,
     "end_time": "2023-09-01T09:45:39.034259",
     "exception": false,
     "start_time": "2023-09-01T09:45:38.530672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f05a5f0b84b268ac0e204c1801522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\n",
    "options = 'ABCDE'\n",
    "indices = list(range(5))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess(example):\n",
    "    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n",
    "    # so we'll copy our question 5 times before tokenizing\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    second_sentence = []\n",
    "    for option in options:\n",
    "        second_sentence.append(example[option])\n",
    "    # Our tokenizer will turn our text into token IDs BERT can understand\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a228dc0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:39.051692Z",
     "iopub.status.busy": "2023-09-01T09:45:39.051409Z",
     "iopub.status.idle": "2023-09-01T09:45:42.672941Z",
     "shell.execute_reply": "2023-09-01T09:45:42.671962Z"
    },
    "papermill": {
     "duration": 3.63279,
     "end_time": "2023-09-01T09:45:42.675312",
     "exception": false,
     "start_time": "2023-09-01T09:45:39.042522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n",
    "# will dynamically pad our questions at batch-time so we don't have to make every question the length\n",
    "# of our longest question.\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2a8bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:42.693990Z",
     "iopub.status.busy": "2023-09-01T09:45:42.692519Z",
     "iopub.status.idle": "2023-09-01T09:45:57.896620Z",
     "shell.execute_reply": "2023-09-01T09:45:57.895642Z"
    },
    "papermill": {
     "duration": 15.215104,
     "end_time": "2023-09-01T09:45:57.898739",
     "exception": false,
     "start_time": "2023-09-01T09:45:42.683635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Some weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n",
    "# make prediction on the private dataset.\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421c2da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:57.917118Z",
     "iopub.status.busy": "2023-09-01T09:45:57.916838Z",
     "iopub.status.idle": "2023-09-01T09:45:58.038572Z",
     "shell.execute_reply": "2023-09-01T09:45:58.037655Z"
    },
    "papermill": {
     "duration": 0.133484,
     "end_time": "2023-09-01T09:45:58.040745",
     "exception": false,
     "start_time": "2023-09-01T09:45:57.907261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The arguments here are selected to run quickly; feel free to play with them.\n",
    "model_dir = 'finetuned_bert'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-7,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26be1b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:45:58.058755Z",
     "iopub.status.busy": "2023-09-01T09:45:58.057939Z",
     "iopub.status.idle": "2023-09-01T09:46:03.507199Z",
     "shell.execute_reply": "2023-09-01T09:46:03.506202Z"
    },
    "papermill": {
     "duration": 5.460877,
     "end_time": "2023-09-01T09:46:03.509896",
     "exception": false,
     "start_time": "2023-09-01T09:45:58.049019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generally it's a bad idea to validate on your training set, but because our training set\n",
    "# for this problem is so small we're going to train on all our data.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c157474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:46:03.527596Z",
     "iopub.status.busy": "2023-09-01T09:46:03.527287Z",
     "iopub.status.idle": "2023-09-01T09:50:25.407506Z",
     "shell.execute_reply": "2023-09-01T09:50:25.406371Z"
    },
    "papermill": {
     "duration": 261.89266,
     "end_time": "2023-09-01T09:50:25.410884",
     "exception": false,
     "start_time": "2023-09-01T09:46:03.518224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 04:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.606072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.604860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.603729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.602718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.601674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.600742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.599930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.599108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.598474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.597945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.597468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.597105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.596817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.596656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.596603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.617630859375, metrics={'train_runtime': 261.5793, 'train_samples_per_second': 11.469, 'train_steps_per_second': 1.434, 'total_flos': 785071118081520.0, 'train_loss': 1.617630859375, 'epoch': 15.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training should take about a minute\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9dfd2db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:25.442108Z",
     "iopub.status.busy": "2023-09-01T09:50:25.441798Z",
     "iopub.status.idle": "2023-09-01T09:50:29.340719Z",
     "shell.execute_reply": "2023-09-01T09:50:29.339823Z"
    },
    "papermill": {
     "duration": 3.911777,
     "end_time": "2023-09-01T09:50:29.342769",
     "exception": false,
     "start_time": "2023-09-01T09:50:25.430992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can actually make predictions on our questions\n",
    "predictions = trainer.predict(tokenized_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592dad86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:29.366955Z",
     "iopub.status.busy": "2023-09-01T09:50:29.365054Z",
     "iopub.status.idle": "2023-09-01T09:50:29.372150Z",
     "shell.execute_reply": "2023-09-01T09:50:29.371241Z"
    },
    "papermill": {
     "duration": 0.020362,
     "end_time": "2023-09-01T09:50:29.374237",
     "exception": false,
     "start_time": "2023-09-01T09:50:29.353875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following function gets the indices of the highest scoring answers for each row\n",
    "# and converts them back to our answer format (A, B, C, D, E)\n",
    "import numpy as np\n",
    "def predictions_to_map_output(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6125210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:29.398022Z",
     "iopub.status.busy": "2023-09-01T09:50:29.397376Z",
     "iopub.status.idle": "2023-09-01T09:50:29.408201Z",
     "shell.execute_reply": "2023-09-01T09:50:29.407334Z"
    },
    "papermill": {
     "duration": 0.025248,
     "end_time": "2023-09-01T09:50:29.410248",
     "exception": false,
     "start_time": "2023-09-01T09:50:29.385000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D E B', 'A C E', 'A C E', 'D B E', 'A B E', 'A D C', 'D B A',\n",
       "       'A E B', 'B C D', 'B C A', 'E A B', 'A D B', 'A C D', 'B E C',\n",
       "       'C D E', 'E B D', 'E C A', 'A B E', 'E C D', 'D A E', 'A E B',\n",
       "       'A E C', 'E A C', 'E C D', 'E A D', 'E C D', 'D A B', 'B E D',\n",
       "       'D C B', 'A D B', 'E C A', 'B E C', 'C A D', 'B E D', 'D E A',\n",
       "       'A C B', 'B C E', 'A C B', 'C E A', 'C E A', 'D E B', 'B D C',\n",
       "       'E B D', 'A B C', 'C D A', 'A B D', 'B D C', 'D C E', 'C D A',\n",
       "       'A B E', 'D A B', 'C A B', 'C A E', 'C E B', 'C B A', 'A D C',\n",
       "       'C D A', 'E B C', 'D E C', 'E A D', 'A C B', 'B E C', 'E B C',\n",
       "       'C B A', 'A E D', 'E C D', 'E C B', 'E A C', 'A C B', 'D E A',\n",
       "       'E D B', 'C A E', 'D A E', 'A C D', 'B E C', 'A B E', 'E A B',\n",
       "       'A C D', 'E D C', 'A B E', 'A B E', 'B D A', 'A D C', 'A D B',\n",
       "       'C A D', 'D B C', 'A D E', 'A E B', 'B D E', 'E D C', 'D B E',\n",
       "       'A E D', 'B E D', 'E B D', 'A E C', 'E D A', 'C E A', 'A E C',\n",
       "       'A B D', 'A D E', 'C E A', 'D C B', 'C E D', 'E C B', 'D E C',\n",
       "       'D E A', 'C D B', 'C A B', 'D A C', 'B A E', 'B E D', 'B D A',\n",
       "       'A C D', 'C E B', 'D A E', 'E C A', 'A B D', 'B A C', 'D A B',\n",
       "       'C B A', 'D C A', 'C D A', 'D A C', 'B D A', 'D E B', 'B A D',\n",
       "       'D B C', 'B D C', 'B E C', 'C A D', 'A C E', 'B A E', 'E C B',\n",
       "       'B A C', 'B E A', 'C E D', 'C D E', 'B E D', 'A E D', 'B C E',\n",
       "       'E B A', 'C D A', 'A E B', 'E B C', 'B D A', 'B A E', 'B D A',\n",
       "       'E B D', 'B C A', 'A D E', 'C A D', 'C A D', 'C A B', 'A D E',\n",
       "       'D A E', 'E C A', 'E D A', 'E C A', 'C B A', 'B A D', 'C E D',\n",
       "       'C A E', 'A B D', 'E A C', 'C A D', 'C D B', 'A D C', 'D A B',\n",
       "       'D E B', 'A E D', 'D E A', 'B E A', 'D C A', 'C A D', 'D B C',\n",
       "       'E B C', 'D B A', 'A E B', 'E A B', 'D B A', 'D E A', 'E B D',\n",
       "       'E B C', 'A C E', 'E D B', 'B A E', 'B E C', 'D A E', 'C D B',\n",
       "       'D E A', 'D E A', 'C D E', 'B C A', 'E A D', 'D E B', 'C B E',\n",
       "       'C A D', 'B E D', 'E C A', 'B C D'], dtype='<U5')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's double check our output looks correct:\n",
    "predictions_to_map_output(predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3705f860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:29.431998Z",
     "iopub.status.busy": "2023-09-01T09:50:29.431743Z",
     "iopub.status.idle": "2023-09-01T09:50:29.462635Z",
     "shell.execute_reply": "2023-09-01T09:50:29.461551Z"
    },
    "papermill": {
     "duration": 0.044695,
     "end_time": "2023-09-01T09:50:29.465046",
     "exception": false,
     "start_time": "2023-09-01T09:50:29.420351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "2   2  Which of the following statements accurately d...   \n",
       "3   3  What is the significance of regularization in ...   \n",
       "4   4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E  \n",
       "0  MOND is a theory that eliminates the observed ...  \n",
       "1  Dynamic scaling refers to the evolution of sel...  \n",
       "2  The triskeles symbol is a representation of th...  \n",
       "3  Regularizing the mass-energy of an electron wi...  \n",
       "4  The angular spacing of features in the diffrac...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can load up our test set to use our model on!\n",
    "# The public test.csv isn't the real dataset (it's actually just a copy of train.csv without the answer column)\n",
    "# but it has the same format as the real test set, so using it is a good way to ensure our code will work when we submit.\n",
    "test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d97b8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:29.493157Z",
     "iopub.status.busy": "2023-09-01T09:50:29.492317Z",
     "iopub.status.idle": "2023-09-01T09:50:29.858428Z",
     "shell.execute_reply": "2023-09-01T09:50:29.857553Z"
    },
    "papermill": {
     "duration": 0.384584,
     "end_time": "2023-09-01T09:50:29.860464",
     "exception": false,
     "start_time": "2023-09-01T09:50:29.475880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d8e8e2797145a8ae8362402c765454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are more verbose/elegant ways of doing this, but if we give our test set a random `answer` column\n",
    "# we can make predictions directly with our trainer.\n",
    "test_df['answer'] = 'A'\n",
    "\n",
    "# Other than that we'll preprocess it in the same way we preprocessed test.csv\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "tokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1917b834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:29.884624Z",
     "iopub.status.busy": "2023-09-01T09:50:29.883083Z",
     "iopub.status.idle": "2023-09-01T09:50:33.963447Z",
     "shell.execute_reply": "2023-09-01T09:50:33.962527Z"
    },
    "papermill": {
     "duration": 4.093992,
     "end_time": "2023-09-01T09:50:33.965614",
     "exception": false,
     "start_time": "2023-09-01T09:50:29.871622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we'll generate our \"real\" predictions on the test set\n",
    "test_predictions = trainer.predict(tokenized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e710d29e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:33.989550Z",
     "iopub.status.busy": "2023-09-01T09:50:33.988723Z",
     "iopub.status.idle": "2023-09-01T09:50:34.010898Z",
     "shell.execute_reply": "2023-09-01T09:50:34.009879Z"
    },
    "papermill": {
     "duration": 0.037891,
     "end_time": "2023-09-01T09:50:34.014887",
     "exception": false,
     "start_time": "2023-09-01T09:50:33.976996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/1317637749.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D E B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A C E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A C E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>D B E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A B E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id prediction\n",
       "0   0      D E B\n",
       "1   1      A C E\n",
       "2   2      A C E\n",
       "3   3      D B E\n",
       "4   4      A B E"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can create our submission using the id column from test.csv\n",
    "submission_df = test_df[['id']]\n",
    "submission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c13143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T09:50:34.038333Z",
     "iopub.status.busy": "2023-09-01T09:50:34.038076Z",
     "iopub.status.idle": "2023-09-01T09:50:34.045864Z",
     "shell.execute_reply": "2023-09-01T09:50:34.045045Z"
    },
    "papermill": {
     "duration": 0.021556,
     "end_time": "2023-09-01T09:50:34.047779",
     "exception": false,
     "start_time": "2023-09-01T09:50:34.026223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once we write our submission file we're good to submit!\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 312.993148,
   "end_time": "2023-09-01T09:50:37.965051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-01T09:45:24.971903",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a43f952d9514e3889ed41da18309335": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_547604ddb0994349964c9495d8c71b32",
       "placeholder": "​",
       "style": "IPY_MODEL_deda3f12bde54a29b30388ccc0346912",
       "value": "100%"
      }
     },
     "12e9edb7b0d24c3f87a423a3694ac065": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3dc8538d8aef49cba62d0a2dd1db993c",
       "placeholder": "​",
       "style": "IPY_MODEL_b6ca88f749ce40489634fc00e66fa0ca",
       "value": " 200/200 [00:00&lt;00:00, 679.06ex/s]"
      }
     },
     "195f6cee86df42b7b7305e8245ebf3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3532dd301011481580fa5550060708e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81020a8bb4e949109c7c3dc8799a2244",
       "placeholder": "​",
       "style": "IPY_MODEL_c1c584aa55214d4893beb2231c79086c",
       "value": "100%"
      }
     },
     "3c0f05a5f0b84b268ac0e204c1801522": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3532dd301011481580fa5550060708e4",
        "IPY_MODEL_47938528a3fb456893521e5dae2de4d4",
        "IPY_MODEL_eae5d60e36094a58b4c9514286ae5984"
       ],
       "layout": "IPY_MODEL_e11728eb5ad44e399c302eddd35b99e3"
      }
     },
     "3dc8538d8aef49cba62d0a2dd1db993c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47938528a3fb456893521e5dae2de4d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce9495ffdb2d4c09b469ee304478ce37",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9136763b7204427e9bf375476b9f0b14",
       "value": 200.0
      }
     },
     "4b0dab35f3834ab49d93fa72df2b2f37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_195f6cee86df42b7b7305e8245ebf3e3",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9d5c082dcfc14e8a9733b15f9c05e5ee",
       "value": 200.0
      }
     },
     "547604ddb0994349964c9495d8c71b32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80d8e8e2797145a8ae8362402c765454": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a43f952d9514e3889ed41da18309335",
        "IPY_MODEL_4b0dab35f3834ab49d93fa72df2b2f37",
        "IPY_MODEL_12e9edb7b0d24c3f87a423a3694ac065"
       ],
       "layout": "IPY_MODEL_eb88dc0990ce4ec78d1dd382ae6f320f"
      }
     },
     "81020a8bb4e949109c7c3dc8799a2244": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9136763b7204427e9bf375476b9f0b14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9d5c082dcfc14e8a9733b15f9c05e5ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b6ca88f749ce40489634fc00e66fa0ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c1c584aa55214d4893beb2231c79086c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cd96157ffab44194ba68af932eb0e3d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce9495ffdb2d4c09b469ee304478ce37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deda3f12bde54a29b30388ccc0346912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dff0f438e38548c79fc81e6b3fcd8ff4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e11728eb5ad44e399c302eddd35b99e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eae5d60e36094a58b4c9514286ae5984": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd96157ffab44194ba68af932eb0e3d1",
       "placeholder": "​",
       "style": "IPY_MODEL_dff0f438e38548c79fc81e6b3fcd8ff4",
       "value": " 200/200 [00:00&lt;00:00, 489.69ex/s]"
      }
     },
     "eb88dc0990ce4ec78d1dd382ae6f320f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
